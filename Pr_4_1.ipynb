{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a239486",
   "metadata": {},
   "source": [
    "# Завдання 1 — Машинний переклад (Transformer) EN ↔ UK (ManyThings)\n",
    "\n",
    "Цей ноутбук робить переклад через готові моделі MarianMT + BLEU + приклади + CSV.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "891fa833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch: 2.9.1+cu128\n",
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import zipfile, random\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import torch\n",
    "import sacrebleu\n",
    "\n",
    "print(\"Torch:\", torch.__version__)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device_id = 0 if device == \"cuda\" else -1\n",
    "print(\"Device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ebf8109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using dataset file: /home/kali/Downloads/data_anal/lab4/ukr.txt\n",
      "Total pairs: 160049\n",
      "Swapped by heuristic: 0\n",
      "Example: ('Go.', 'Йди.')\n"
     ]
    }
   ],
   "source": [
    "LAB_DIR = Path(r\"/home/kali/Downloads/data_anal/lab4\")\n",
    "\n",
    "zip_path = LAB_DIR / \"ukr-eng.zip\"\n",
    "extract_dir = LAB_DIR / \"manythings_ukr_eng\"\n",
    "ukr_txt = LAB_DIR / \"ukr.txt\"\n",
    "\n",
    "def pick_txt_file() -> Path:\n",
    "    \n",
    "    if ukr_txt.exists():\n",
    "        return ukr_txt\n",
    "\n",
    "    \n",
    "    if zip_path.exists():\n",
    "        extract_dir.mkdir(exist_ok=True)\n",
    "        with zipfile.ZipFile(zip_path, \"r\") as zf:\n",
    "            zf.extractall(extract_dir)\n",
    "\n",
    "        txts = sorted(extract_dir.rglob(\"*.txt\"))\n",
    "        if not txts:\n",
    "            raise FileNotFoundError(\"У ukr-eng.zip не знайдено .txt після розпакування.\")\n",
    "\n",
    "        \n",
    "        for p in txts:\n",
    "            if p.name.lower() == \"ukr.txt\":\n",
    "                return p\n",
    "\n",
    "\n",
    "        return txts[0]\n",
    "\n",
    "    \n",
    "    txts = sorted(LAB_DIR.rglob(\"*.txt\"))\n",
    "    if not txts:\n",
    "        raise FileNotFoundError(\n",
    "            f\"Не знайдено ні ukr.txt, ні ukr-eng.zip, ні будь-якого .txt у {LAB_DIR}.\\n\"\n",
    "            \"Поклади ukr.txt або ukr-eng.zip у цю папку.\"\n",
    "        )\n",
    "\n",
    "    \n",
    "    for p in txts:\n",
    "        if \"ukr\" in p.name.lower():\n",
    "            return p\n",
    "\n",
    "    return txts[0]\n",
    "\n",
    "data_txt = pick_txt_file()\n",
    "print(\"Using dataset file:\", data_txt)\n",
    "\n",
    "# Парсимо рядки: очікуємо таби (EN\\tUK\\t...) або (UK\\tEN\\t...) ---\n",
    "def lang_score(s: str):\n",
    "    latin = sum(ch.isalpha() and ('A' <= ch <= 'Z' or 'a' <= ch <= 'z') for ch in s)\n",
    "    cyr = sum(ch in \"АБВГҐДЕЄЖЗИІЇЙКЛМНОПРСТУФХЦЧШЩЬЮЯабвгґдеєжзиіїйклмнопрстуфхцчшщьюя\" for ch in s)\n",
    "    return latin, cyr\n",
    "\n",
    "pairs = []\n",
    "swapped = 0\n",
    "with open(data_txt, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "    for line in f:\n",
    "        parts = line.rstrip(\"\\n\").split(\"\\t\")\n",
    "        if len(parts) < 2:\n",
    "            continue\n",
    "        a, b = parts[0].strip(), parts[1].strip()\n",
    "        if not a or not b:\n",
    "            continue\n",
    "\n",
    "        a_lat, a_cyr = lang_score(a)\n",
    "        b_lat, b_cyr = lang_score(b)\n",
    "\n",
    "        # якщо (a схоже на EN) і (b схоже на UK) -> (EN, UK)\n",
    "        if a_lat >= a_cyr and b_cyr >= b_lat:\n",
    "            en, uk = a, b\n",
    "        # якщо навпаки -> свап\n",
    "        elif b_lat >= b_cyr and a_cyr >= a_lat:\n",
    "            en, uk = b, a\n",
    "            swapped += 1\n",
    "        else:\n",
    "            # неясно — залишаємо як (a,b)\n",
    "            en, uk = a, b\n",
    "\n",
    "        pairs.append((en, uk))\n",
    "\n",
    "print(\"Total pairs:\", len(pairs))\n",
    "print(\"Swapped by heuristic:\", swapped)\n",
    "print(\"Example:\", pairs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8feab398",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>en</th>\n",
       "      <th>uk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It's all so sad.</td>\n",
       "      <td>Це все так сумно.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You should've kissed Tom.</td>\n",
       "      <td>Тобі слід було поцілувати Тома.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I spent a lot of time listening to music.</td>\n",
       "      <td>Я провів багато часу, слухаючи музику.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I'm sloshed.</td>\n",
       "      <td>Я під мухою.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tom's comfortable.</td>\n",
       "      <td>Тому зручно.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          en  \\\n",
       "0                           It's all so sad.   \n",
       "1                  You should've kissed Tom.   \n",
       "2  I spent a lot of time listening to music.   \n",
       "3                               I'm sloshed.   \n",
       "4                         Tom's comfortable.   \n",
       "\n",
       "                                       uk  \n",
       "0                       Це все так сумно.  \n",
       "1         Тобі слід було поцілувати Тома.  \n",
       "2  Я провів багато часу, слухаючи музику.  \n",
       "3                            Я під мухою.  \n",
       "4                            Тому зручно.  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "random.seed(42)\n",
    "random.shuffle(pairs)\n",
    "\n",
    "MAX_PAIRS = 8000\n",
    "VAL_N     = 500\n",
    "\n",
    "pairs = pairs[:MAX_PAIRS]\n",
    "val_pairs = pairs[:VAL_N]\n",
    "\n",
    "val_df = pd.DataFrame(val_pairs, columns=[\"en\", \"uk\"])\n",
    "val_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bcde858b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quick examples EN→UK:\n",
      "- Do not open suspicious attachments.\n",
      "   Не відкривайте підозрілі долучення.\n",
      "- Please confirm your password using the link.\n",
      "   Будь ласка, підтвердіть ваш пароль за допомогою посилання.\n",
      "\n",
      "Quick examples UK→EN:\n",
      "- Не відкривайте підозрілі вкладення в листах.\n",
      "   Do not open suspicious letters.\n",
      "- Будь ласка, підтвердіть пароль за посиланням.\n",
      "   Please confirm the link password.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "MODEL_EN_UK = \"Helsinki-NLP/opus-mt-en-uk\"\n",
    "MODEL_UK_EN = \"Helsinki-NLP/opus-mt-uk-en\"\n",
    "\n",
    "en2uk = pipeline(\"translation\", model=MODEL_EN_UK, device=device_id)\n",
    "uk2en = pipeline(\"translation\", model=MODEL_UK_EN, device=device_id)\n",
    "\n",
    "print(\"Quick examples EN→UK:\")\n",
    "for t in [\"Do not open suspicious attachments.\", \"Please confirm your password using the link.\"]:\n",
    "    print(\"-\", t)\n",
    "    print(\"  \", en2uk(t, max_length=128)[0][\"translation_text\"])\n",
    "\n",
    "print(\"\\nQuick examples UK→EN:\")\n",
    "for t in [\"Не відкривайте підозрілі вкладення в листах.\", \"Будь ласка, підтвердіть пароль за посиланням.\"]:\n",
    "    print(\"-\", t)\n",
    "    print(\"  \", uk2en(t, max_length=128)[0][\"translation_text\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8764d1e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU: 100.00000000000004\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# BLEU on validation (EN→UK)\n",
    "preds, refs = [], []\n",
    "for en, uk in val_pairs:\n",
    "    out = en2uk(en, max_length=128)[0][\"translation_text\"]\n",
    "    preds.append(out)\n",
    "    refs.append([uk])\n",
    "\n",
    "bleu = sacrebleu.corpus_bleu(preds, refs)\n",
    "print(\"BLEU:\", bleu.score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9417394e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: results_task1_translation_en2uk.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>en</th>\n",
       "      <th>uk</th>\n",
       "      <th>uk_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It's all so sad.</td>\n",
       "      <td>Це все так сумно.</td>\n",
       "      <td>Це все так сумно.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You should've kissed Tom.</td>\n",
       "      <td>Тобі слід було поцілувати Тома.</td>\n",
       "      <td>Тобі слід було поцілувати Тома.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I spent a lot of time listening to music.</td>\n",
       "      <td>Я провів багато часу, слухаючи музику.</td>\n",
       "      <td>Я провів багато часу, слухаючи музику.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I'm sloshed.</td>\n",
       "      <td>Я під мухою.</td>\n",
       "      <td>Я приголомшений.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tom's comfortable.</td>\n",
       "      <td>Тому зручно.</td>\n",
       "      <td>Тому зручно.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          en  \\\n",
       "0                           It's all so sad.   \n",
       "1                  You should've kissed Tom.   \n",
       "2  I spent a lot of time listening to music.   \n",
       "3                               I'm sloshed.   \n",
       "4                         Tom's comfortable.   \n",
       "\n",
       "                                       uk  \\\n",
       "0                       Це все так сумно.   \n",
       "1         Тобі слід було поцілувати Тома.   \n",
       "2  Я провів багато часу, слухаючи музику.   \n",
       "3                            Я під мухою.   \n",
       "4                            Тому зручно.   \n",
       "\n",
       "                                  uk_pred  \n",
       "0                       Це все так сумно.  \n",
       "1         Тобі слід було поцілувати Тома.  \n",
       "2  Я провів багато часу, слухаючи музику.  \n",
       "3                        Я приголомшений.  \n",
       "4                            Тому зручно.  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "out_df = val_df.copy()\n",
    "out_df[\"uk_pred\"] = preds\n",
    "out_df.to_csv(\"results_task1_translation_en2uk.csv\", index=False, encoding=\"utf-8\")\n",
    "print(\"Saved: results_task1_translation_en2uk.csv\")\n",
    "out_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beea4691",
   "metadata": {},
   "source": [
    "\n",
    "## mini fine-tune\n",
    "Якщо треба показати навчання — ставимо `DO_TRAIN=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ab53701",
   "metadata": {},
   "outputs": [],
   "source": [
    "DO_TRAIN = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "633902ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kali/Downloads/data_anal/lab4/.venv/lib/python3.13/site-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc566b996ffc4bd5918bc59c04f64dc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49da521598d34b1b99311628646b9229",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kali/Downloads/data_anal/lab4/.venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='30' max='30' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [30/30 00:19, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.790700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.582200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.582400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.453500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.602900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.687500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kali/Downloads/data_anal/lab4/.venv/lib/python3.13/site-packages/transformers/modeling_utils.py:3918: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[61586]]}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved finetuned to mt_en_uk_mini_finetune/final\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if DO_TRAIN:\n",
    "    from datasets import Dataset\n",
    "    from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq\n",
    "    from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "\n",
    "    train_pairs = pairs[VAL_N:VAL_N+2000]\n",
    "    train_df = pd.DataFrame(train_pairs, columns=[\"en\", \"uk\"])\n",
    "\n",
    "    ds_train = Dataset.from_pandas(train_df)\n",
    "    ds_val   = Dataset.from_pandas(val_df)\n",
    "\n",
    "    base_model = \"Helsinki-NLP/opus-mt-en-uk\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(base_model)\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(base_model).to(device)\n",
    "\n",
    "    max_len = 96\n",
    "\n",
    "    def preprocess(batch):\n",
    "        x = tokenizer(batch[\"en\"], truncation=True, max_length=max_len)\n",
    "        y = tokenizer(text_target=batch[\"uk\"], truncation=True, max_length=max_len)\n",
    "        x[\"labels\"] = y[\"input_ids\"]\n",
    "        return x\n",
    "\n",
    "    tok_train = ds_train.map(preprocess, batched=True, remove_columns=ds_train.column_names)\n",
    "    tok_val   = ds_val.map(preprocess, batched=True, remove_columns=ds_val.column_names)\n",
    "\n",
    "    collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)\n",
    "\n",
    "    args = Seq2SeqTrainingArguments(\n",
    "        output_dir=\"mt_en_uk_mini_finetune\",\n",
    "        overwrite_output_dir=True,\n",
    "        per_device_train_batch_size=4,\n",
    "        per_device_eval_batch_size=4,\n",
    "        learning_rate=5e-5,\n",
    "        max_steps=30,\n",
    "        logging_steps=5,\n",
    "        eval_strategy=\"no\",\n",
    "        save_strategy=\"no\",\n",
    "        predict_with_generate=True,\n",
    "        report_to=\"none\",\n",
    "    )\n",
    "\n",
    "    trainer = Seq2SeqTrainer(\n",
    "        model=model,\n",
    "        args=args,\n",
    "        train_dataset=tok_train,\n",
    "        eval_dataset=tok_val,\n",
    "        data_collator=collator,\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "    model.save_pretrained(\"mt_en_uk_mini_finetune/final\")\n",
    "    tokenizer.save_pretrained(\"mt_en_uk_mini_finetune/final\")\n",
    "    print(\"Saved finetuned to mt_en_uk_mini_finetune/final\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf44073-b93a-432b-95f1-073620d60f92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  },
  "title": "Lab Task 1: Translation EN<->UK (ManyThings, local zip)"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
